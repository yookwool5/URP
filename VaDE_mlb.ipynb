{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9f3c470-b7e8-4d69-9bb8-69f99a04de0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: easydict in ./anaconda3/lib/python3.11/site-packages (1.10)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install easydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dec63dff-aabe-4898-b19e-5c0190f2dc6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in ./anaconda3/lib/python3.11/site-packages (2.13.0)\n",
      "Requirement already satisfied: tensorflow-macos==2.13.0 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in ./anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in ./anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in ./anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in ./anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in ./anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in ./anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (4.24.2)\n",
      "Requirement already satisfied: setuptools in ./anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in ./anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (1.57.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in ./anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in ./anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in ./anaconda3/lib/python3.11/site-packages (from tensorflow-macos==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.13.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in ./anaconda3/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in ./anaconda3/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./anaconda3/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./anaconda3/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./anaconda3/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./anaconda3/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in ./anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./anaconda3/lib/python3.11/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in ./anaconda3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./anaconda3/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71560149-18ca-4c07-bd9a-c7f258d573a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1: Train Loss = 7.3487\n",
      "Epoch   2: Train Loss = 7.2245\n",
      "Epoch   3: Train Loss = 7.1578\n",
      "Epoch   4: Train Loss = 7.1777\n",
      "Epoch   5: Train Loss = 7.0865\n",
      "Epoch   6: Train Loss = 7.0804\n",
      "Epoch   7: Train Loss = 7.0681\n",
      "Epoch   8: Train Loss = 7.1075\n",
      "Epoch   9: Train Loss = 7.1023\n",
      "Epoch  10: Train Loss = 7.0982\n",
      "Epoch  11: Train Loss = 7.0755\n",
      "Epoch  12: Train Loss = 7.0702\n",
      "Epoch  13: Train Loss = 7.1167\n",
      "Epoch  14: Train Loss = 7.0678\n",
      "Epoch  15: Train Loss = 7.0598\n",
      "Epoch  16: Train Loss = 7.0639\n",
      "Epoch  17: Train Loss = 7.0543\n",
      "Epoch  18: Train Loss = 7.0710\n",
      "Epoch  19: Train Loss = 7.0773\n",
      "Epoch  20: Train Loss = 7.0576\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import easydict\n",
    "from vade import AutoEncoderForPretrain, VaDE\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "N_CLASSES = 5\n",
    "\n",
    "\n",
    "def train(model, data_loader, optimizer, device, epoch):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    for x in data_loader:\n",
    "        batch_size = x.size(0)\n",
    "        x = x.to(device).view(-1, 11)\n",
    "        recon_x = model(x)\n",
    "        loss = F.binary_cross_entropy(recon_x, x, reduction='sum') / batch_size\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print('Epoch {:>3}: Train Loss = {:.4f}'.format(\n",
    "        epoch, total_loss / len(data_loader)))\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv):\n",
    "        self.inp = csv.values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inp) \n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        inp = torch.FloatTensor(self.inp[idx])\n",
    "        return inp \n",
    "\n",
    "def main():\n",
    "    # parser = argparse.ArgumentParser(\n",
    "    #     description='Train VaDE with MNIST dataset',\n",
    "    #     formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "    # parser.add_argument('--epochs', '-e',\n",
    "    #                     help='Number of epochs.',\n",
    "    #                     type=int, default=20)\n",
    "    # parser.add_argument('--gpu', '-g',\n",
    "    #                     help='GPU id. (Negative number indicates CPU)',\n",
    "    #                     type=int, default=-1)\n",
    "    # parser.add_argument('--learning-rate', '-l',\n",
    "    #                     help='Learning Rate.',\n",
    "    #                     type=float, default=0.001)\n",
    "    # parser.add_argument('--batch-size', '-b',\n",
    "    #                     help='Batch size.',\n",
    "    #                     type=int, default=128)\n",
    "    # parser.add_argument('--out', '-o',\n",
    "    #                     help='Output path.',\n",
    "    #                     type=str, default='./vade_parameter.pth')\n",
    "    # args = parser.parse_args()\n",
    "    args = easydict.EasyDict ({\n",
    "        \"epochs\" : 20,\n",
    "        \"gpu\" : -1,\n",
    "        \"batch_size\" : 1,\n",
    "        \"learning_rate\" : 0.001,\n",
    "        \"out\" : './vade_parameter.pth'\n",
    "    })\n",
    "\n",
    "    if_use_cuda = torch.cuda.is_available() and args.gpu >= 0\n",
    "    device = torch.device('cuda:{}'.format(args.gpu) if if_use_cuda else 'cpu')\n",
    "\n",
    "    # dataset = datasets.MNIST('./data', train=True, download=True,\n",
    "    #                                transform=transforms.ToTensor())\n",
    "    CSV_PATH = './stats2021.csv'\n",
    "    scaler = MinMaxScaler()\n",
    "    mlb = pd.read_csv(CSV_PATH)\n",
    "    mlb = mlb.iloc[0:, 4:15]\n",
    "    scaler.fit(mlb)\n",
    "    norm_mlb = scaler.transform(mlb)\n",
    "    norm_mlb = pd.DataFrame(norm_mlb)\n",
    "    dataset = CustomDataset(norm_mlb)\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=args.batch_size, shuffle=True,\n",
    "        num_workers=0, pin_memory=if_use_cuda)\n",
    "\n",
    "    pretrain_model = AutoEncoderForPretrain(11, 2).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(pretrain_model.parameters(),\n",
    "                                 lr=args.learning_rate)\n",
    "\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        train(pretrain_model, data_loader, optimizer, device, epoch)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        x = torch.vstack([data[0] for data in dataset]).view(-1, 11).to(device)\n",
    "        z = pretrain_model.encode(x).cpu()\n",
    "\n",
    "    pretrain_model = pretrain_model.cpu()\n",
    "    state_dict = pretrain_model.state_dict()\n",
    "\n",
    "    gmm = GaussianMixture(n_components=10, covariance_type='diag')\n",
    "    gmm.fit(z)\n",
    "\n",
    "    model = VaDE(N_CLASSES, 11, 2)\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "    model._pi.data = torch.log(torch.from_numpy(gmm.weights_)).float()\n",
    "    model.mu.data = torch.from_numpy(gmm.means_).float()\n",
    "    model.logvar.data = torch.log(torch.from_numpy(gmm.covariances_)).float()\n",
    "\n",
    "    torch.save(model.state_dict(), args.out)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5dc2cd87-ba26-4408-aa6b-87fa90eef433",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1: Train Loss = 9.2861\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 101\u001b[0m\n\u001b[1;32m     98\u001b[0m     writer\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 101\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[30], line 95\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, args\u001b[38;5;241m.\u001b[39mepochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     94\u001b[0m     train(model, data_loader, optimizer, device, epoch, writer)\n\u001b[0;32m---> 95\u001b[0m     test(model, data_loader, device, epoch, writer)\n\u001b[1;32m     96\u001b[0m     lr_scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     98\u001b[0m writer\u001b[38;5;241m.\u001b[39mclose()\n",
      "Cell \u001b[0;32mIn[30], line 40\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(model, data_loader, device, epoch, writer)\u001b[0m\n\u001b[1;32m     38\u001b[0m gain \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((N_CLASSES, N_CLASSES), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m xs, ts \u001b[38;5;129;01min\u001b[39;00m data_loader:\n\u001b[1;32m     41\u001b[0m         xs, ts \u001b[38;5;241m=\u001b[39m xs\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m11\u001b[39m), ts\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;28mprint\u001b[39m (xs, ts)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "from munkres import Munkres\n",
    "from sklearn.manifold import TSNE\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "import easydict\n",
    "from vade import VaDE, lossfun, ordloss \n",
    "\n",
    "N_CLASSES = 5\n",
    "PLOT_NUM_PER_CLASS = 128\n",
    "\n",
    "\n",
    "def train(model, data_loader, optimizer, device, epoch, writer):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    for x in data_loader:\n",
    "        x = x.to(device).view(-1, 11)\n",
    "        recon_x, mu, logvar = model(x)    ###forward 자동호출\n",
    "        loss = lossfun(model, x, recon_x, mu, logvar)\n",
    "        #ord_loss = (ordloss(model, x, 10,2))/20\n",
    "        total_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    writer.add_scalar('Loss/train', total_loss / len(data_loader), epoch)\n",
    "    print('Epoch {:>3}: Train Loss = {:.4f}'.format(\n",
    "        epoch, total_loss / len(data_loader)))\n",
    "\n",
    "\n",
    "def test(model, data_loader, device, epoch, writer):\n",
    "    model.eval()\n",
    "\n",
    "    gain = torch.zeros((N_CLASSES, N_CLASSES), dtype=torch.int, device=device)\n",
    "    with torch.no_grad():\n",
    "        for xs, ts in data_loader:\n",
    "            xs, ts = xs.to(device).view(-1, 11), ts.to(device)\n",
    "            print (xs, ts)\n",
    "            ys = model.classify(xs)\n",
    "            print(ys)\n",
    "            for t, y in zip(ts, ys):\n",
    "                gain[t, y] += 1\n",
    "        cost = (torch.max(gain) - gain).cpu().numpy()\n",
    "        assign = Munkres().compute(cost)\n",
    "        acc = torch.sum(gain[tuple(zip(*assign))]).float() / torch.sum(gain)\n",
    "    writer.add_scalar('Acc/test', acc.item(), epoch)\n",
    "    writer.add_figure('LatentSpace', fig, epoch)\n",
    "\n",
    "\n",
    "def main():\n",
    "    args = easydict.EasyDict ({\n",
    "        \"epochs\" : 50,\n",
    "        \"gpu\" : -1,\n",
    "        \"learning_rate\" : 0.002,\n",
    "        \"batch_size\" : 10,\n",
    "        \"pretrain\" : None\n",
    "    })\n",
    "\n",
    "    if_use_cuda = torch.cuda.is_available() and args.gpu >= 0\n",
    "    device = torch.device('cuda:{}'.format(args.gpu) if if_use_cuda else 'cpu')\n",
    "\n",
    "    CSV_PATH = './stats2021.csv'\n",
    "    scaler = MinMaxScaler()\n",
    "    mlb = pd.read_csv(CSV_PATH)\n",
    "    mlb = mlb.iloc[0:, 4:15]\n",
    "    scaler.fit(mlb)\n",
    "    norm_mlb = scaler.transform(mlb)\n",
    "    norm_mlb = pd.DataFrame(norm_mlb)\n",
    "    dataset = CustomDataset(norm_mlb)\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=args.batch_size, shuffle=True,\n",
    "        num_workers=0, pin_memory=if_use_cuda)\n",
    "\n",
    "    # For plotting\n",
    "\n",
    "    model = VaDE(N_CLASSES, 11, 2)\n",
    "    if args.pretrain:\n",
    "        model.load_state_dict(torch.load(args.pretrain))\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "    # LR decreases every 10 epochs with a decay rate of 0.9\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "        optimizer, step_size=10, gamma=0.9)\n",
    "\n",
    "    # TensorBoard\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        train(model, data_loader, optimizer, device, epoch, writer)\n",
    "        test(model, data_loader, device, epoch, writer)\n",
    "        lr_scheduler.step()\n",
    "\n",
    "    writer.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e5507d2-0e78-40c4-9834-b168daf225be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-4d80529c28d72f5c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-4d80529c28d72f5c\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=runs "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
